# GTZAN Music Genre Classifier

Welcome to our project, a deep learningâ€“powered music genre classification system trained on the GTZAN dataset. This repository contains all code, configurations, and documentation needed to reproduce our results and deploy the model in a Flutter/Dart Android application.

---

## ğŸš€ Project Overview

Our model is a hybrid **CNNâ€“LSTM** model that processes audio as mel-spectrogram slices and captures both local timbral textures and temporal dynamics for high-accuracy genre recognition. By combining convolutional layers with a recurrent layer, our system achieves **94.51 %** overall accuracy on the GTZAN benchmark. In addition to research-grade performance, weâ€™ve packaged the trained model as a **TensorFlow Lite** module ready for real-time, on-device inference in a Flutter mobile app.

---

## âœ¨ Key Features

- **State-of-the-Art Accuracy**  
  Achieves 94.51 % test accuracy, with macro-averaged precision, recall, and F1-score around 94 %.

- **Hybrid Architecture**  
  - Three Conv2D layers (32 â†’ 64 â†’ 128 filters; 3Ã—3 kernels; ReLU activations; max-pooling; dropout)  
  - LSTM layer with 64 units for temporal modeling  
  - Dense + softmax output layer for 10 genre classes

- **Robust Preprocessing**  
  - Splits each 30 s track into 4 s chunks with 2 s overlap  
  - Computes 128-band log-mel spectrograms  
  - Optional data augmentation: time-stretching, pitch-shifting

- **End-to-End Pipeline**  
  Includes data loading, preprocessing, feature extraction, model training, evaluation, and mobile deployment.

- **Mobile Deployment**  
  - Conversion to TFLite for lightweight on-device inference  
  - Flutter/Dart integration example for Android

---

## ğŸ“¦ Repository Structure

```

MLProjectCode/src/         
â”œâ”€â”€ download.py                  # Download GTZAN dataset
â”œâ”€â”€ preprocess.py                # Audio preprocessing and feature extraction
â”œâ”€â”€ augmentations.py             # Data augmentation scripts
â”œâ”€â”€ train.py                     # Model training script
â”œâ”€â”€ evaluate.py                  # Model evaluation script
â”œâ”€â”€ test.py                      # Optional testing utilities
â”œâ”€â”€ requirements.txt             # Python dependencies

android/                        
â”œâ”€â”€ AndroidManifest.xml          # Android config (part of Flutter app)
â”œâ”€â”€ build.gradle                 # Android build file
â””â”€â”€ ...                          # Other native Android project files

assets/                         
â”œâ”€â”€ gtzan/                       # Raw GTZAN dataset
â”œâ”€â”€ processed/                   # Preprocessed spectrogram data
â”œâ”€â”€ model.tflite                 # Converted TFLite model for mobile
â”œâ”€â”€ weights.h5                   # Trained Keras model weights
â”œâ”€â”€ metrics.csv                  # Evaluation metrics
â”œâ”€â”€ confusion_matrix.png         # Confusion matrix plot
â””â”€â”€ spectrogram_sample.png       # Example mel-spectrogram image

build/                          
â””â”€â”€ ...                          # Auto-generated build artifacts

hugging/                        
â””â”€â”€ config.json                  # Config for Hugging Face (optional)

ios/                            
â””â”€â”€ Runner.xcodeproj             # iOS Flutter project config

lib/                            
â”œâ”€â”€ main.dart                    # Entry point for Flutter app
â””â”€â”€ ...                          # Dart files (UI, controllers, services)

linux/                          
â””â”€â”€ deploy.sh                    # Linux deployment script

macos/                          
â””â”€â”€ deploy.sh                    # macOS deployment script

test/                           
â”œâ”€â”€ test_main.dart               # Flutter unit tests
â””â”€â”€ test_model.py                # Python model testing script

web/                            
â””â”€â”€ index.html                   # Flutter web build entry point

windows/                        
â””â”€â”€ deploy.bat                   # Windows deployment script

"Apk file Video"/               
â””â”€â”€ demo.mp4                     # Screen recording or demo video of APK in action

LICENSE                          # Project license (Apache 2.0)

MusicClassifier.apk              # Pre-built Android APK for quick testing

README.md                        # Project overview and instructions (you are here)

documentation/                  
â”œâ”€â”€ report.pdf                   # Final report / paper
â””â”€â”€ architecture_diagram.png     # System architecture diagram

pubspec.yaml                     # Flutter project configuration

pubspec.lock                     # Locked Dart package version


````

---

## ğŸ”§ Installation

1. **Clone the repository**  
   ```bash
   git clone https://github.com/yourusername/gtzan-music-classifier.git
   cd gtzan-music-classifier

2. **Set up a Python environment**

   ```bash
   python3 -m venv venv
   source venv/bin/activate

3. **Install dependencies**

   ```bash
   pip install -r requirements.txt

4. **Download GTZAN dataset**

   ```bash
   python data/download.py --output_dir ./data/gtzan
   ```

---

## ğŸ¬ Usage

### Preprocess & Augment Data

```bash
python data/preprocess.py --input_dir ./data/gtzan --output_dir ./data/processed
```

### Train the Model

```bash
python models/train.py \
  --data_dir ./data/processed \
  --epochs 100 \
  --batch_size 32 \
  --learning_rate 0.001 \
  --output_model ./results/weights.h5
```

### Evaluate Performance

```bash
python models/evaluate.py \
  --model_path ./results/weights.h5 \
  --data_dir ./data/processed \
  --metrics_output ./results/metrics.csv
```

---

## ğŸ“ˆ Results

* **Accuracy:** 94.51 %
* **Precision:** 0.945
* **Recall:** 0.942
* **F1-score:** 0.943

A full per-genre breakdown and confusion matrix are available in `results/metrics.csv` and `results/confusion_matrix.png`.

---

## ğŸ“± Mobile App Integration

To try real-time on-device inference:

1. **Open the Flutter project**

   ```bash
   cd app
   flutter pub get
   ```

2. **Place the TFLite model**
   Copy `results/model.tflite` into `app/assets/`.

3. **Run on Android**

   ```bash
   flutter run
   ```

The app records a short audio clip and displays the predicted genre along with a confidence score. See `app/screenshots/` for example outputs.

---

## ğŸ¤ Contributing

We welcome contributions! Please fork the repo, create a feature branch, and submit a pull request. Whether itâ€™s improving model accuracy, adding new augmentation techniques, or refining the mobile UI, your expertise and ideas are invaluable.

## Drive Video Link
https://drive.google.com/file/d/1EuMoPz9W_E0SdqWrYXwbcJtRLfDmfPde/view?usp=drive_link
